# ðŸ“¦ UK E-commerce Data Analysis (Excel | SQL | Python | Power BI)

## ðŸ“Œ Project Overview
This project analyzes UK-based e-commerce transaction data to uncover insights related to sales performance, customer behavior, product demand, returns, and time-based purchasing patterns.

It demonstrates a **complete, end-to-end data analytics workflow**, starting from raw data cleaning and ending with an interactive business dashboard.

The dataset contains **line-level transaction data**, meaning each order can include multiple products. Special care was taken to aggregate data at the correct business level (order, customer, product, and time) to ensure accurate insights.

---

## ðŸ”„ End-to-End Workflow
1. **Excel** â€“ Data cleaning and preprocessing  
2. **SQL (MySQL)** â€“ Metric validation and structured analysis  
3. **Python (Jupyter Notebook)** â€“ Exploratory & behavioral analysis  
4. **Power BI** â€“ Interactive dashboard for stakeholder reporting  

---

## ðŸ›  Tools & Technologies
- **Excel** â€“ Data cleaning & preprocessing  
- **MySQL** â€“ Data querying and analysis  
- **MySQL Workbench** â€“ SQL development environment  
- **Python** â€“ Exploratory data analysis  
  - pandas  
  - matplotlib  
  - seaborn  
- **Jupyter Notebook** â€“ Python analysis documentation  
- **Power BI Desktop** â€“ Dashboarding & visualization  

---

## ðŸ§¹ Data Cleaning & Preparation (Excel)
The raw dataset was cleaned and prepared in **Excel** before loading into MySQL.

### Key data cleaning steps:
- Removed fully empty rows
- Standardized column formats
- Handled missing `CustomerID` values by labeling them as `Unknown`
- Ensured identifier columns (`InvoiceNo`, `StockCode`) were treated as text due to alphanumeric values
- Created derived columns:
  - `InvoiceYear`
  - `InvoiceMonth`
  - `InvoiceHour`
  - `InvoiceDay`
  - `LineRevenue` (Quantity Ã— UnitPrice)
- Preserved negative quantities to correctly represent product returns
- Ensured date and time fields were properly formatted

The cleaned dataset served as the **single source of truth** for all downstream analysis.

---

## ðŸ“‚ Dataset Access
The cleaned dataset (~36 MB) exceeds GitHubâ€™s file size limit.

ðŸ”— **Download cleaned dataset:**  
https://docs.google.com/spreadsheets/d/1EO8B-grat7NyiSrfpEpPmLuE7Yo0aFzJ68UhQJNU2PA/edit?usp=sharing

---

## ðŸ“‚ Project Structure
```text
â”œâ”€â”€ data_cleaning_excel/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ phase_1_data_understanding.sql
â”‚   â”œâ”€â”€ phase_2_SALES_REVENUE_ANALYSIS.sql
â”‚   â”œâ”€â”€ phase3_PRODUCT_PERFORMANCE.sql
â”‚   â”œâ”€â”€ PHASE4_CUSTOMER_ANALYSIS.sql
â”‚   â”œâ”€â”€ PHASE5_TIME_BEHAVIOR_ANALYSIS.sql
â”‚   â”œâ”€â”€ PHASE6_DATA_QUALITY.sql
â”‚   â””â”€â”€ sql_upwork_project1.sql
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ ecommerce_analysis.ipynb
â”‚
â”œâ”€â”€ powerbi/
â”‚   â”œâ”€â”€ dashboard_overview.png
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md
